{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTbccl7FnN3_","executionInfo":{"status":"ok","timestamp":1714373347870,"user_tz":-120,"elapsed":20785,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}},"outputId":"5d22cc6c-edb5-48e1-df6e-6cd656fc476f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3EKXcmMz5am","outputId":"26a2f00d-c0f4-4b8d-aa3a-40d60c5715bd","executionInfo":{"status":"ok","timestamp":1714374508711,"user_tz":-120,"elapsed":611,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'ID': '__land_reform_NN_1', 'term': 'land reform', 'type': 'noun', 'sentence': ''}\n"]}],"source":["# test reading data\n","\n","import json\n","from sklearn.model_selection import train_test_split\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/llms4ol/wordnet/data/wordnet_train.json\", \"r\") as json_data:\n","    wordnet_json = json.loads(json_data.read())\n","    json_data.close()\n","\n","print(wordnet_json[0])\n","\n","# transform json data to pandas dataframe\n","#wordnet_df = pd.DataFrame.from_dict(wordnet_json)\n","#print(wordnet_df.head())\n","\n","# train-test split data\n","wordnet_train, wordnet_test = train_test_split(wordnet_json, test_size=0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suKIIyVUVogw","outputId":"b4bda7fa-0da8-457c-c63f-d544fc446474","executionInfo":{"status":"ok","timestamp":1714373459186,"user_tz":-120,"elapsed":74747,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/297.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/297.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Collecting transformers\n","  Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.0\n","    Uninstalling transformers-4.40.0:\n","      Successfully uninstalled transformers-4.40.0\n","Successfully installed transformers-4.40.1\n"]}],"source":["# start preparing for QA pipeline\n","! pip install -U accelerate\n","! pip install -U transformers"]},{"cell_type":"code","source":["# prepare train dataset\n","wordnet_train_data = []\n","for i in wordnet_train:\n","  wordnet_train_data.append(i)\n","\n","\n","# prepare test dataset\n","wordnet_test_data = []\n","for i in wordnet_test:\n","  wordnet_test_data.append(i)"],"metadata":{"id":"zMaIVVMgB53V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers\n","!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3l2YV0mBHGK5","outputId":"555f3888-cedc-412b-baa9-015aa3e6bd8d","executionInfo":{"status":"ok","timestamp":1714373481408,"user_tz":-120,"elapsed":14429,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n","Collecting xxhash (from evaluate)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n","Collecting huggingface-hub>=0.7.0 (from evaluate)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Installing collected packages: xxhash, dill, responses, multiprocess, huggingface-hub, datasets, evaluate\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 evaluate-0.4.1 huggingface-hub-0.22.2 multiprocess-0.70.16 responses-0.18.0 xxhash-3.4.1\n"]}]},{"cell_type":"code","source":["import torch\n","import json\n","from tqdm import tqdm\n","import torch.nn as nn\n","from torch.optim import Adam\n","import nltk\n","import spacy\n","import string\n","import evaluate  # Bleu\n","from torch.utils.data import Dataset, DataLoader, RandomSampler\n","import pandas as pd\n","import numpy as np\n","import transformers\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"TTK_luP8HOAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_NAME = \"google/flan-t5-small\"\n","TOKENIZER = T5TokenizerFast.from_pretrained(MODEL_NAME)\n","MODEL = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n","OPTIMIZER = Adam(MODEL.parameters(), lr=0.00001)\n","Q_LEN = 512   # Question Length\n","T_LEN = 512    # Target Length\n","BATCH_SIZE = 4\n","DEVICE = \"cuda:0\""],"metadata":{"id":"fQFZnPX0LMUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a Dataframe from train data\n","wordnet_train_df = pd.DataFrame(wordnet_train_data)\n","# convert df values to string\n","wordnet_train_df = wordnet_train_df.applymap(str)\n","\n","# Create a Dataframe from test data\n","wordnet_test_df = pd.DataFrame(wordnet_test_data)\n","# convert df values to string\n","wordnet_test_df = wordnet_test_df.applymap(str)"],"metadata":{"id":"VycXBFrZ4cUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class QA_Dataset(Dataset):\n","    def __init__(self, tokenizer, dataframe, q_len, t_len):\n","        self.tokenizer = tokenizer\n","        self.q_len = q_len\n","        self.t_len = t_len\n","        self.data = dataframe\n","        self.term = self.data[\"term\"]\n","        self.sentence = self.data[\"sentence\"]\n","        self.ttype = self.data['type']\n","\n","    def __len__(self):\n","        return len(self.term)\n","\n","    def __getitem__(self, idx):\n","        term = self.term[idx]\n","        sentence = self.sentence[idx]\n","        ttype = self.ttype[idx]\n","\n","        term_tokenized = self.tokenizer(term, sentence, max_length=self.q_len, padding=\"max_length\",\n","                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n","        type_tokenized = self.tokenizer(ttype, max_length=self.t_len, padding=\"max_length\",\n","                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n","\n","        labels = torch.tensor(type_tokenized[\"input_ids\"], dtype=torch.long)\n","        labels[labels == 0] = -100\n","\n","        return {\n","            \"input_ids\": torch.tensor(term_tokenized[\"input_ids\"], dtype=torch.long),\n","            \"attention_mask\": torch.tensor(term_tokenized[\"attention_mask\"], dtype=torch.long),\n","            \"labels\": labels,\n","            \"decoder_attention_mask\": torch.tensor(type_tokenized[\"attention_mask\"], dtype=torch.long)\n","        }"],"metadata":{"id":"jpRD5Xlxx2Xm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wn_train_dataset = QA_Dataset(TOKENIZER, wordnet_train_df, Q_LEN, T_LEN)\n","wn_test_dataset = QA_Dataset(TOKENIZER, wordnet_test_df, Q_LEN, T_LEN)\n","\n","train_loader = DataLoader(wn_train_dataset, batch_size=BATCH_SIZE)\n","val_loader = DataLoader(wn_test_dataset, batch_size=BATCH_SIZE)"],"metadata":{"id":"01VbmiPLMgu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#torch.cuda.empty_cache()\n","MODEL.to('cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sT7HdEN-mwtT","outputId":"374a7314-9e45-4297-d3aa-734d8fc257da","executionInfo":{"status":"ok","timestamp":1714374550274,"user_tz":-120,"elapsed":545,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["train_loss = 0\n","val_loss = 0\n","train_batch_count = 0\n","val_batch_count = 0\n","\n","for epoch in range(5):\n","    MODEL.train()\n","    for batch in tqdm(train_loader, desc=\"Training batches\"):\n","        input_ids = batch[\"input_ids\"].to(DEVICE)\n","        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n","        labels = batch[\"labels\"].to(DEVICE)\n","        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n","\n","        outputs = MODEL(\n","                          input_ids=input_ids,\n","                          attention_mask=attention_mask,\n","                          labels=labels,\n","                          decoder_attention_mask=decoder_attention_mask\n","                        )\n","\n","        OPTIMIZER.zero_grad()\n","        outputs.loss.backward()\n","        OPTIMIZER.step()\n","        train_loss += outputs.loss.item()\n","        train_batch_count += 1\n","\n","    #Evaluation\n","    MODEL.eval()\n","    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n","        input_ids = batch[\"input_ids\"].to(DEVICE)\n","        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n","        labels = batch[\"labels\"].to(DEVICE)\n","        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n","\n","        outputs = MODEL(\n","                          input_ids=input_ids,\n","                          attention_mask=attention_mask,\n","                          labels=labels,\n","                          decoder_attention_mask=decoder_attention_mask\n","                        )\n","\n","        OPTIMIZER.zero_grad()\n","        outputs.loss.backward()\n","        OPTIMIZER.step()\n","        val_loss += outputs.loss.item()\n","        val_batch_count += 1\n","\n","    print(f\"{epoch+1}/{5} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mg9Enw4WMnUZ","outputId":"7f349c98-7dda-4099-c79f-7faad140e61c","executionInfo":{"status":"ok","timestamp":1714381267311,"user_tz":-120,"elapsed":6619579,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Training batches: 100%|██████████| 7098/7098 [15:38<00:00,  7.56it/s]\n","Validation batches: 100%|██████████| 3042/3042 [06:24<00:00,  7.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1/5 -> Train loss: 0.17253155328383843\tValidation loss: 0.06402620651098698\n"]},{"output_type":"stream","name":"stderr","text":["Training batches: 100%|██████████| 7098/7098 [15:38<00:00,  7.56it/s]\n","Validation batches: 100%|██████████| 3042/3042 [06:24<00:00,  7.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["2/5 -> Train loss: 0.12507161001761682\tValidation loss: 0.05356932875270597\n"]},{"output_type":"stream","name":"stderr","text":["Training batches: 100%|██████████| 7098/7098 [15:38<00:00,  7.57it/s]\n","Validation batches: 100%|██████████| 3042/3042 [06:25<00:00,  7.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["3/5 -> Train loss: 0.10405499887054523\tValidation loss: 0.04691070953986259\n"]},{"output_type":"stream","name":"stderr","text":["Training batches: 100%|██████████| 7098/7098 [15:37<00:00,  7.57it/s]\n","Validation batches: 100%|██████████| 3042/3042 [06:25<00:00,  7.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4/5 -> Train loss: 0.091722005889927\tValidation loss: 0.0421861065176478\n"]},{"output_type":"stream","name":"stderr","text":["Training batches: 100%|██████████| 7098/7098 [15:40<00:00,  7.55it/s]\n","Validation batches: 100%|██████████| 3042/3042 [06:25<00:00,  7.88it/s]"]},{"output_type":"stream","name":"stdout","text":["5/5 -> Train loss: 0.08308814391048032\tValidation loss: 0.0384906199354733\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["MODEL.save_pretrained(\"flan-t5-small_wordnet_model\")\n","TOKENIZER.save_pretrained(\"flan-t5-small_wordnet_tokenizer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFF1oknapQg8","outputId":"6461b34c-6a67-4e69-90c5-20107f033825","executionInfo":{"status":"ok","timestamp":1714381291412,"user_tz":-120,"elapsed":788,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('flan-t5-small_wordnet_tokenizer/tokenizer_config.json',\n"," 'flan-t5-small_wordnet_tokenizer/special_tokens_map.json',\n"," 'flan-t5-small_wordnet_tokenizer/spiece.model',\n"," 'flan-t5-small_wordnet_tokenizer/added_tokens.json',\n"," 'flan-t5-small_wordnet_tokenizer/tokenizer.json')"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# Saved files\n","\"\"\"('flan-t5-small_wordnet_tokenizer/tokenizer_config.json',\n"," 'flan-t5-small_wordnet_tokenizer/special_tokens_map.json',\n"," 'flan-t5-small_wordnet_tokenizer/spiece.model',\n","'flan-t5-small_wordnet_tokenizer/added_tokens.json',\n","'flan-t5-small_wordnet_tokenizer/tokenizer.json')\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"jjlB-cw1Ms-L","outputId":"5c19dc78-1685-44df-f622-8e735d12d88f","executionInfo":{"status":"ok","timestamp":1714381358249,"user_tz":-120,"elapsed":572,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"('flan-t5-small_wordnet_tokenizer/tokenizer_config.json',\\n 'flan-t5-small_wordnet_tokenizer/special_tokens_map.json',\\n 'flan-t5-small_wordnet_tokenizer/spiece.model',\\n'flan-t5-small_wordnet_tokenizer/added_tokens.json',\\n'flan-t5-small_wordnet_tokenizer/tokenizer.json')\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["import numpy as np\n","\n","def precision_at_k(actual, predicted):\n","    act_set = set(actual)\n","    pred_set = set(predicted)\n","    result = len(act_set & pred_set) / float(len(predicted))\n","    return result*100\n","\n","def apk(actual, predicted, k):\n","    \"\"\"\n","    Computes the average precision at k.\n","    This function computes the average prescision at k between two lists of\n","    items.\n","    Parameters\n","    ----------\n","    actual : list\n","             A list of elements that are to be predicted (order doesn't matter)\n","    predicted : list\n","                A list of predicted elements (order does matter)\n","    k : int\n","        The maximum number of predicted elements\n","    Returns\n","    -------\n","    score : double\n","            The average precision at k over the input lists\n","    \"\"\"\n","    if not actual:\n","        return 0.0\n","    if len(predicted)>k:\n","        predicted = predicted[:k]\n","    score = 0.0\n","    num_hits = 0.0\n","    for i,p in enumerate(predicted):\n","        # first condition checks whether it is valid prediction\n","        # second condition checks if prediction is not repeated\n","        if p in actual and p not in predicted[:i]:\n","            num_hits += 1.0\n","            score += num_hits / (i+1.0)\n","    return score / min(len(actual), k)\n","\n","\n","def mapk(actual, predicted, k):\n","    \"\"\"\n","    Computes the mean average precision at k.\n","    This function computes the mean average prescision at k between two lists\n","    of lists of items.\n","    Parameters\n","    ----------\n","    actual : list\n","             A list of lists of elements that are to be predicted\n","             (order doesn't matter in the lists)\n","    predicted : list\n","                A list of lists of predicted elements\n","                (order matters in the lists)\n","    k : int,\n","        The maximum number of predicted elements\n","    Returns\n","    -------\n","    score : double\n","            The mean average precision at k over the input lists\n","    \"\"\"\n","    return np.mean([apk(a, p, k) for a,p in zip(actual, predicted)])\n","\n","\n","class EvaluationMetrics:\n","\n","    def __init__(self, ks:list, metric=\"map\") -> None:\n","        self.ks = ks\n","        self.metric=metric\n","\n","    def evaluate(self, actual:list, predicted:list):\n","        if self.metric == \"map\":\n","            return self.MAP(actual, predicted)\n","        else:\n","            return self.AP(actual, predicted)\n","\n","    def MAP(self, actual:list, predicted:list):\n","        results_dict = {}\n","        for k in self.ks:\n","            results_dict[\"MAP@\"+str(k)] = mapk(actual=actual, predicted=predicted, k=k)\n","        return results_dict\n","\n","    def AP(self, actual:list, predicted:list):\n","        results_dict = {}\n","        for k in self.ks:\n","            results_dict[\"AP@\"+str(k)] = [apk(actual=actual, predicted=predicted, k=k)\n","                                          for a, p in zip(actual, predicted)]\n","        return results_dict\n","\n","def predict_answer(sentence, term, ref_type=None):\n","    inputs = TOKENIZER(term, sentence, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n","\n","    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n","    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n","\n","    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n","\n","    predicted_type = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n","\n","    if ref_type:\n","        # Load the MAP@K metric for K=1\n","        score = mapk([ref_type], [predicted_type], 1)\n","\n","        print(\"Sentence: \\n\", sentence)\n","        print(\"\\n\")\n","        print(\"Term: \\n\", term)\n","        return {\n","            \"Reference Type: \": ref_type,\n","            \"Predicted Type: \": predicted_type,\n","            \"MAP@1: \": score\n","        }\n","    else:\n","        return predicted_type"],"metadata":{"id":"23_173BJLq-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test predictions\n","sentence = wordnet_train_df.iloc[0][\"sentence\"]\n","term = wordnet_train_df.iloc[0][\"term\"]\n","ttype = wordnet_train_df.iloc[0][\"type\"]\n","\n","print(\"*** PREDICTION:\", predict_answer(sentence, term, ttype))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFiXHwwMNZuF","outputId":"281cc8e6-d0c3-476c-a92b-1114e4f99d0c","executionInfo":{"status":"ok","timestamp":1714381372182,"user_tz":-120,"elapsed":570,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: \n"," \n","\n","\n","Term: \n"," animal oil\n","*** PREDICTION: {'Reference Type: ': 'noun', 'Predicted Type: ': 'noun', 'MAP@1: ': 1.0}\n"]}]},{"cell_type":"code","source":["from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n","\n","# test loading model\n","MODEL = T5ForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/llms4ol/wordnet/model/flan-t5-small_wordnet_model\")\n","TOKENIZER = T5TokenizerFast.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/llms4ol/wordnet/model/flan-t5-small_wordnet_tokenizer\")"],"metadata":{"id":"zvodHUIBPl-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL.to('cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVemUoV7pHOL","outputId":"90b47c84-f453-4273-bf4f-b242b2144a8c","executionInfo":{"status":"ok","timestamp":1714381406353,"user_tz":-120,"elapsed":334,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# test predictions\n","reference_types = []\n","predicted_types = []\n","for index, row in wordnet_test_df.iterrows():\n","  sentence = row[\"sentence\"]\n","  term = row[\"term\"]\n","  ttype = row[\"type\"]\n","\n","  predicted_type = predict_answer(sentence, term, ttype)[\"Predicted Type: \"]\n","  reference_types.append(ttype)\n","  predicted_types.append(predicted_type)\n","\n","print(\"MAP@1 score:\", mapk(reference_types, predicted_types, 1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O664EZy2pBPN","outputId":"7005b097-3d1c-46b5-b131-8dd26e34c9c3","executionInfo":{"status":"ok","timestamp":1714382002174,"user_tz":-120,"elapsed":586259,"user":{"displayName":"habiakl dsti","userId":"12970270001325048550"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n"," flame nettle\n","Sentence: \n"," \n","\n","\n","Term: \n"," payena\n","Sentence: \n"," \n","\n","\n","Term: \n"," ochre\n","Sentence: \n"," \n","\n","\n","Term: \n"," sarcocystis\n","Sentence: \n"," \n","\n","\n","Term: \n"," supervision\n","Sentence: \n"," \n","\n","\n","Term: \n"," agrimony\n","Sentence: \n"," they lost everything in the fire\n","\n","\n","Term: \n"," fire\n","Sentence: \n"," the car couldn't make it up the rise\n","\n","\n","Term: \n"," upgrade\n","Sentence: \n"," The enemy has been shelling us all day\n","\n","\n","Term: \n"," shell\n","Sentence: \n"," \n","\n","\n","Term: \n"," relaxant\n","Sentence: \n"," he used pliers as a bender\n","\n","\n","Term: \n"," bender\n","Sentence: \n"," she likes the touch of silk on her skin\n","\n","\n","Term: \n"," touch sensation\n","Sentence: \n"," \n","\n","\n","Term: \n"," titfer\n","Sentence: \n"," the results of the election will be announced tonight\n","\n","\n","Term: \n"," election\n","Sentence: \n"," \n","\n","\n","Term: \n"," myrmecophaga\n","Sentence: \n"," \n","\n","\n","Term: \n"," furlong\n","Sentence: \n"," \n","\n","\n","Term: \n"," sericocarpus\n","Sentence: \n"," \n","\n","\n","Term: \n"," total\n","Sentence: \n"," \n","\n","\n","Term: \n"," white sturgeon\n","Sentence: \n"," \n","\n","\n","Term: \n"," four-minute man\n","Sentence: \n"," they pulled the canoe up on the bank\n","\n","\n","Term: \n"," bank\n","Sentence: \n"," The men were thrilled by a loud whistle blow\n","\n","\n","Term: \n"," thrill\n","Sentence: \n"," she recognized his handwriting\n","\n","\n","Term: \n"," handwriting\n","Sentence: \n"," \n","\n","\n","Term: \n"," cranberry\n","Sentence: \n"," \n","\n","\n","Term: \n"," wind instrument\n","Sentence: \n"," \n","\n","\n","Term: \n"," sea lawyer\n","Sentence: \n"," \n","\n","\n","Term: \n"," hot rod\n","Sentence: \n"," \n","\n","\n","Term: \n"," alphabet\n","Sentence: \n"," \n","\n","\n","Term: \n"," fault\n","Sentence: \n"," a small knot of women listened to his sermon\n","\n","\n","Term: \n"," knot\n","Sentence: \n"," \n","\n","\n","Term: \n"," wycliffe\n","Sentence: \n"," \n","\n","\n","Term: \n"," executive officer\n","Sentence: \n"," \n","\n","\n","Term: \n"," provost marshal\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus aethionema\n","Sentence: \n"," the pull up the hill had him breathing harder\n","\n","\n","Term: \n"," pulling\n","Sentence: \n"," he put the cup back in the saucer\n","\n","\n","Term: \n"," cup\n","Sentence: \n"," \n","\n","\n","Term: \n"," centrefold\n","Sentence: \n"," \n","\n","\n","Term: \n"," twin\n","Sentence: \n"," this accords with the recent study by Hill and Dale\n","\n","\n","Term: \n"," written report\n","Sentence: \n"," \n","\n","\n","Term: \n"," january 1\n","Sentence: \n"," \n","\n","\n","Term: \n"," tegu\n","Sentence: \n"," \n","\n","\n","Term: \n"," dardanelles campaign\n","Sentence: \n"," permissible behavior in school\n","\n","\n","Term: \n"," permissible\n","Sentence: \n"," they are trying to determine the cause of the crash\n","\n","\n","Term: \n"," cause\n","Sentence: \n"," \n","\n","\n","Term: \n"," proposition\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus ambrosia\n","Sentence: \n"," I could not think of him in disassociation from his wife\n","\n","\n","Term: \n"," disassociation\n","Sentence: \n"," \n","\n","\n","Term: \n"," pot plant\n","Sentence: \n"," I am reading a good book on economics\n","\n","\n","Term: \n"," book\n","Sentence: \n"," An enemy plane flew by\n","\n","\n","Term: \n"," fly by\n","Sentence: \n"," \n","\n","\n","Term: \n"," fire tongs\n","Sentence: \n"," \n","\n","\n","Term: \n"," coucal\n","Sentence: \n"," \n","\n","\n","Term: \n"," vantage\n","Sentence: \n"," \n","\n","\n","Term: \n"," varna\n","Sentence: \n"," \n","\n","\n","Term: \n"," starry saxifrage\n","Sentence: \n"," \n","\n","\n","Term: \n"," patrick henry\n","Sentence: \n"," the entrance was guarded by ranks of policemen\n","\n","\n","Term: \n"," rank\n","Sentence: \n"," \n","\n","\n","Term: \n"," northern territory\n","Sentence: \n"," \n","\n","\n","Term: \n"," dilation\n","Sentence: \n"," he was here for a little while\n","\n","\n","Term: \n"," while\n","Sentence: \n"," The QE2 will sail to Southampton tomorrow\n","\n","\n","Term: \n"," navigate\n","Sentence: \n"," \n","\n","\n","Term: \n"," duke\n","Sentence: \n"," \n","\n","\n","Term: \n"," bond\n","Sentence: \n"," \n","\n","\n","Term: \n"," ordnance survey\n","Sentence: \n"," \n","\n","\n","Term: \n"," sex symbol\n","Sentence: \n"," you can compute the area of a square if you know the length of its sides\n","\n","\n","Term: \n"," square\n","Sentence: \n"," post a sign\n","\n","\n","Term: \n"," put up\n","Sentence: \n"," His colleagues worked out his interesting idea\n","\n","\n","Term: \n"," work out\n","Sentence: \n"," \n","\n","\n","Term: \n"," glide\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus canis\n","Sentence: \n"," \n","\n","\n","Term: \n"," skin\n","Sentence: \n"," \n","\n","\n","Term: \n"," menuridae\n","Sentence: \n"," \n","\n","\n","Term: \n"," snow\n","Sentence: \n"," they used to think that intelligence is what an intelligence test tests\n","\n","\n","Term: \n"," iq test\n","Sentence: \n"," \n","\n","\n","Term: \n"," twaddle\n","Sentence: \n"," \n","\n","\n","Term: \n"," formula\n","Sentence: \n"," \n","\n","\n","Term: \n"," septette\n","Sentence: \n"," \n","\n","\n","Term: \n"," north africa\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus cystophora\n","Sentence: \n"," \n","\n","\n","Term: \n"," hydrokinetics\n","Sentence: \n"," \n","\n","\n","Term: \n"," estimation\n","Sentence: \n"," \n","\n","\n","Term: \n"," private property\n","Sentence: \n"," \n","\n","\n","Term: \n"," credentials\n","Sentence: \n"," \n","\n","\n","Term: \n"," want\n","Sentence: \n"," \n","\n","\n","Term: \n"," mesoderm\n","Sentence: \n"," \n","\n","\n","Term: \n"," kansas city\n","Sentence: \n"," guard my possessions while I'm away\n","\n","\n","Term: \n"," ward\n","Sentence: \n"," They named their son David\n","\n","\n","Term: \n"," name\n","Sentence: \n"," He left behind all his possessions when he moved to Europe\n","\n","\n","Term: \n"," leave behind\n","Sentence: \n"," \n","\n","\n","Term: \n"," tooth root\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus cnicus\n","Sentence: \n"," \n","\n","\n","Term: \n"," player\n","Sentence: \n"," \n","\n","\n","Term: \n"," viscaceae\n","Sentence: \n"," \n","\n","\n","Term: \n"," stenotus acaulis\n","Sentence: \n"," \n","\n","\n","Term: \n"," shore patrol\n","Sentence: \n"," \n","\n","\n","Term: \n"," wonderment\n","Sentence: \n"," \n","\n","\n","Term: \n"," toss\n","Sentence: \n"," \n","\n","\n","Term: \n"," melia\n","Sentence: \n"," \n","\n","\n","Term: \n"," xerophyllum\n","Sentence: \n"," \n","\n","\n","Term: \n"," lieutenant junior grade\n","Sentence: \n"," \n","\n","\n","Term: \n"," sheaf\n","Sentence: \n"," \n","\n","\n","Term: \n"," kaw river\n","Sentence: \n"," \n","\n","\n","Term: \n"," coliseum\n","Sentence: \n"," \n","\n","\n","Term: \n"," stall\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus idesia\n","Sentence: \n"," his failure to pass the test\n","\n","\n","Term: \n"," failure\n","Sentence: \n"," \n","\n","\n","Term: \n"," talwin\n","Sentence: \n"," \n","\n","\n","Term: \n"," george ii\n","Sentence: \n"," \n","\n","\n","Term: \n"," lucknow\n","Sentence: \n"," I will work hard to improve my grades\n","\n","\n","Term: \n"," work\n","Sentence: \n"," \n","\n","\n","Term: \n"," dictate\n","Sentence: \n"," \n","\n","\n","Term: \n"," orly\n","Sentence: \n"," \n","\n","\n","Term: \n"," twins\n","Sentence: \n"," \n","\n","\n","Term: \n"," sleuthhound\n","Sentence: \n"," \n","\n","\n","Term: \n"," graves' disease\n","Sentence: \n"," I will work hard to improve my grades\n","\n","\n","Term: \n"," work\n","Sentence: \n"," \n","\n","\n","Term: \n"," twiddler\n","Sentence: \n"," \n","\n","\n","Term: \n"," bmdo\n","Sentence: \n"," \n","\n","\n","Term: \n"," queer duck\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus carnegiea\n","Sentence: \n"," \n","\n","\n","Term: \n"," norinyl\n","Sentence: \n"," \n","\n","\n","Term: \n"," novelist\n","Sentence: \n"," \n","\n","\n","Term: \n"," thorazine\n","Sentence: \n"," \n","\n","\n","Term: \n"," edward vii\n","Sentence: \n"," \n","\n","\n","Term: \n"," overhead\n","Sentence: \n"," \n","\n","\n","Term: \n"," yellow jessamine\n","Sentence: \n"," \n","\n","\n","Term: \n"," shoji\n","Sentence: \n"," \n","\n","\n","Term: \n"," gestalt psychology\n","Sentence: \n"," his story brought tears to her eyes\n","\n","\n","Term: \n"," tear\n","Sentence: \n"," the house yonder\n","\n","\n","Term: \n"," yonder\n","Sentence: \n"," \n","\n","\n","Term: \n"," whited sepulchre\n","Sentence: \n"," \n","\n","\n","Term: \n"," face mask\n","Sentence: \n"," \n","\n","\n","Term: \n"," clip artist\n","Sentence: \n"," \n","\n","\n","Term: \n"," confection\n","Sentence: \n"," \n","\n","\n","Term: \n"," pipe\n","Sentence: \n"," \n","\n","\n","Term: \n"," shrimp\n","Sentence: \n"," \n","\n","\n","Term: \n"," reckoning\n","Sentence: \n"," in the 19th century Prussia led the economic and political unification of the German states\n","\n","\n","Term: \n"," prussia\n","Sentence: \n"," \n","\n","\n","Term: \n"," sarcocephalus\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus datura\n","Sentence: \n"," \n","\n","\n","Term: \n"," guinea worm\n","Sentence: \n"," \n","\n","\n","Term: \n"," vaccinum\n","Sentence: \n"," we are in a transitional stage in which many former ideas must be revised or rejected\n","\n","\n","Term: \n"," stage\n","Sentence: \n"," the President likes to jog every morning\n","\n","\n","Term: \n"," united states president\n","Sentence: \n"," a good soak put life back in the wagon\n","\n","\n","Term: \n"," soaking\n","Sentence: \n"," \n","\n","\n","Term: \n"," ocyurus\n","Sentence: \n"," \n","\n","\n","Term: \n"," saddam hussein\n","Sentence: \n"," the attack wiped out our forward bases\n","\n","\n","Term: \n"," base\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus chondrus\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus anabrus\n","Sentence: \n"," \n","\n","\n","Term: \n"," thorax\n","Sentence: \n"," \n","\n","\n","Term: \n"," myosotis scorpiodes\n","Sentence: \n"," \n","\n","\n","Term: \n"," mechanical drawing\n","Sentence: \n"," The bugs pinged the lamp shade\n","\n","\n","Term: \n"," ping\n","Sentence: \n"," they stood on the grey cement beside the pool\n","\n","\n","Term: \n"," cement\n","Sentence: \n"," \n","\n","\n","Term: \n"," piciformes\n","Sentence: \n"," \n","\n","\n","Term: \n"," colorado river\n","Sentence: \n"," \n","\n","\n","Term: \n"," mass\n","Sentence: \n"," \n","\n","\n","Term: \n"," toffee apple\n","Sentence: \n"," \n","\n","\n","Term: \n"," forgetfulness\n","Sentence: \n"," \n","\n","\n","Term: \n"," round clam\n","Sentence: \n"," a critical time in the school's history\n","\n","\n","Term: \n"," history\n","Sentence: \n"," \n","\n","\n","Term: \n"," ionophoresis\n","Sentence: \n"," \n","\n","\n","Term: \n"," tangibleness\n","Sentence: \n"," \n","\n","\n","Term: \n"," tzetze fly\n","Sentence: \n"," \n","\n","\n","Term: \n"," ononis\n","Sentence: \n"," \n","\n","\n","Term: \n"," catecholamine\n","Sentence: \n"," \n","\n","\n","Term: \n"," wrecking bar\n","Sentence: \n"," \n","\n","\n","Term: \n"," infiltration\n","Sentence: \n"," \n","\n","\n","Term: \n"," lyric poem\n","Sentence: \n"," rural people show more devotion and unselfishness than do their urban cousins\n","\n","\n","Term: \n"," unselfishness\n","Sentence: \n"," \n","\n","\n","Term: \n"," python\n","Sentence: \n"," offer prayers to the gods\n","\n","\n","Term: \n"," offer up\n","Sentence: \n"," judging on a scale of 1 to 10\n","\n","\n","Term: \n"," scale\n","Sentence: \n"," \n","\n","\n","Term: \n"," rouge\n","Sentence: \n"," \n","\n","\n","Term: \n"," fertility\n","Sentence: \n"," \n","\n","\n","Term: \n"," field pea\n","Sentence: \n"," The men trap foxes\n","\n","\n","Term: \n"," trammel\n","Sentence: \n"," a diet high in protein\n","\n","\n","Term: \n"," protein\n","Sentence: \n"," \n","\n","\n","Term: \n"," rio de janeiro\n","Sentence: \n"," he accepted it on appro\n","\n","\n","Term: \n"," appro\n","Sentence: \n"," \n","\n","\n","Term: \n"," tibeto-burman language\n","Sentence: \n"," his consecration to study\n","\n","\n","Term: \n"," consecration\n","Sentence: \n"," The burglar jimmied the lock\n","\n","\n","Term: \n"," pry\n","Sentence: \n"," \n","\n","\n","Term: \n"," symphalangus\n","Sentence: \n"," I wish I could undo my actions\n","\n","\n","Term: \n"," undo\n","Sentence: \n"," \n","\n","\n","Term: \n"," family dactylopteridae\n","Sentence: \n"," The advent of the automobile may have altered the growth pattern of the city\n","\n","\n","Term: \n"," alter\n","Sentence: \n"," \n","\n","\n","Term: \n"," stealth\n","Sentence: \n"," \n","\n","\n","Term: \n"," united states liquid unit\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus echinacea\n","Sentence: \n"," The enemy recommenced hostilities after a few days of quiet\n","\n","\n","Term: \n"," recommence\n","Sentence: \n"," Please inspect your father's will carefully\n","\n","\n","Term: \n"," inspect\n","Sentence: \n"," printers once kept the type for capitals and for small letters in separate cases; capitals were kept in the upper half of the type case and so became known as upper-case letters\n","\n","\n","Term: \n"," uppercase\n","Sentence: \n"," \n","\n","\n","Term: \n"," confederate\n","Sentence: \n"," The scientists set up a shock wave\n","\n","\n","Term: \n"," effect\n","Sentence: \n"," \n","\n","\n","Term: \n"," volcano\n","Sentence: \n"," \n","\n","\n","Term: \n"," hood\n","Sentence: \n"," \n","\n","\n","Term: \n"," secret agent\n","Sentence: \n"," \n","\n","\n","Term: \n"," persecution\n","Sentence: \n"," Her smile denoted that she agreed\n","\n","\n","Term: \n"," denote\n","Sentence: \n"," \n","\n","\n","Term: \n"," groundcover\n","Sentence: \n"," events suddenly took an awkward turn\n","\n","\n","Term: \n"," twist\n","Sentence: \n"," \n","\n","\n","Term: \n"," brokerage\n","Sentence: \n"," \n","\n","\n","Term: \n"," old world buffalo\n","Sentence: \n"," \n","\n","\n","Term: \n"," indian meal\n","Sentence: \n"," \n","\n","\n","Term: \n"," prefrontal lobe\n","Sentence: \n"," These operators commute with each other\n","\n","\n","Term: \n"," commute\n","Sentence: \n"," take action\n","\n","\n","Term: \n"," take\n","Sentence: \n"," The horse bounded across the meadow\n","\n","\n","Term: \n"," bound\n","Sentence: \n"," We provided the room with an electrical heater\n","\n","\n","Term: \n"," provide\n","Sentence: \n"," \n","\n","\n","Term: \n"," bauxite\n","Sentence: \n"," \n","\n","\n","Term: \n"," assibilate\n","Sentence: \n"," \n","\n","\n","Term: \n"," drumfish\n","Sentence: \n"," \n","\n","\n","Term: \n"," trotsky\n","Sentence: \n"," retouch the roots\n","\n","\n","Term: \n"," retouch\n","Sentence: \n"," The surgeon cauterized the wart\n","\n","\n","Term: \n"," cauterize\n","Sentence: \n"," \n","\n","\n","Term: \n"," olive tree\n","Sentence: \n"," \n","\n","\n","Term: \n"," tentaculata\n","Sentence: \n"," \n","\n","\n","Term: \n"," crenellation\n","Sentence: \n"," \n","\n","\n","Term: \n"," nefud\n","Sentence: \n"," \n","\n","\n","Term: \n"," mere\n","Sentence: \n"," \n","\n","\n","Term: \n"," outdraw\n","Sentence: \n"," \n","\n","\n","Term: \n"," venesection\n","Sentence: \n"," \n","\n","\n","Term: \n"," impairment\n","Sentence: \n"," \n","\n","\n","Term: \n"," river limpet\n","Sentence: \n"," \n","\n","\n","Term: \n"," volvocales\n","Sentence: \n"," Bullets were spatting down on us\n","\n","\n","Term: \n"," spat\n","Sentence: \n"," Please focus on your studies and not on your hobbies\n","\n","\n","Term: \n"," focus\n","Sentence: \n"," \n","\n","\n","Term: \n"," nullipara\n","Sentence: \n"," \n","\n","\n","Term: \n"," rotator cuff\n","Sentence: \n"," \n","\n","\n","Term: \n"," pouteria\n","Sentence: \n"," The violins in this piece dissonated disturbingly\n","\n","\n","Term: \n"," dissonate\n","Sentence: \n"," \n","\n","\n","Term: \n"," kobe\n","Sentence: \n"," We resumed the negotiations\n","\n","\n","Term: \n"," resume\n","Sentence: \n"," \n","\n","\n","Term: \n"," octopod\n","Sentence: \n"," 2 is a modulus of 5 and 9\n","\n","\n","Term: \n"," modulus\n","Sentence: \n"," \n","\n","\n","Term: \n"," toe\n","Sentence: \n"," \n","\n","\n","Term: \n"," woman's clothing\n","Sentence: \n"," \n","\n","\n","Term: \n"," perfumery\n","Sentence: \n"," \n","\n","\n","Term: \n"," zombie\n","Sentence: \n"," Put away your worries\n","\n","\n","Term: \n"," toss out\n","Sentence: \n"," \n","\n","\n","Term: \n"," rhizophoraceae\n","Sentence: \n"," \n","\n","\n","Term: \n"," salpinx\n","Sentence: \n"," \n","\n","\n","Term: \n"," sardine\n","Sentence: \n"," \n","\n","\n","Term: \n"," auriculare\n","Sentence: \n"," \n","\n","\n","Term: \n"," linnaeus\n","Sentence: \n"," \n","\n","\n","Term: \n"," protuberate\n","Sentence: \n"," \n","\n","\n","Term: \n"," split\n","Sentence: \n"," \n","\n","\n","Term: \n"," rustbelt\n","Sentence: \n"," \n","\n","\n","Term: \n"," chinese brown sauce\n","Sentence: \n"," they went to a movie every Saturday night\n","\n","\n","Term: \n"," film\n","Sentence: \n"," \n","\n","\n","Term: \n"," fin\n","Sentence: \n"," \n","\n","\n","Term: \n"," winter heliotrope\n","Sentence: \n"," \n","\n","\n","Term: \n"," sod\n","Sentence: \n"," \n","\n","\n","Term: \n"," artificiality\n","Sentence: \n"," `maison' means `house' in French\n","\n","\n","Term: \n"," signify\n","Sentence: \n"," \n","\n","\n","Term: \n"," economic process\n","Sentence: \n"," \n","\n","\n","Term: \n"," reticulum\n","Sentence: \n"," \n","\n","\n","Term: \n"," pax\n","Sentence: \n"," \n","\n","\n","Term: \n"," hanukkah\n","Sentence: \n"," \n","\n","\n","Term: \n"," winged elm\n","Sentence: \n"," \n","\n","\n","Term: \n"," tl\n","Sentence: \n"," \n","\n","\n","Term: \n"," muscari\n","Sentence: \n"," Decorate the room for the party\n","\n","\n","Term: \n"," ornament\n","Sentence: \n"," The paper discredited the politician with its nasty commentary\n","\n","\n","Term: \n"," discredit\n","Sentence: \n"," \n","\n","\n","Term: \n"," mib\n","Sentence: \n"," \n","\n","\n","Term: \n"," family alopiidae\n","Sentence: \n"," \n","\n","\n","Term: \n"," nonpartisanship\n","Sentence: \n"," the wall had a smooth texture\n","\n","\n","Term: \n"," texture\n","Sentence: \n"," water condenses\n","\n","\n","Term: \n"," condense\n","Sentence: \n"," \n","\n","\n","Term: \n"," slaughter\n","Sentence: \n"," \n","\n","\n","Term: \n"," pork\n","Sentence: \n"," \n","\n","\n","Term: \n"," lift\n","Sentence: \n"," the audience consisted largely of repeaters who had seen the movie many times\n","\n","\n","Term: \n"," repeater\n","Sentence: \n"," he was called on for an aliyah\n","\n","\n","Term: \n"," aliyah\n","Sentence: \n"," the hum of distant traffic\n","\n","\n","Term: \n"," humming\n","Sentence: \n"," he accepted their problems with composure and she with equanimity\n","\n","\n","Term: \n"," equanimity\n","Sentence: \n"," he studied medicine at Harvard\n","\n","\n","Term: \n"," practice of medicine\n","Sentence: \n"," \n","\n","\n","Term: \n"," citrus fruit\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus antennaria\n","Sentence: \n"," \n","\n","\n","Term: \n"," shoulder\n","Sentence: \n"," We anchored at Baltimore\n","\n","\n","Term: \n"," drop anchor\n","Sentence: \n"," The book portrays the actor as a selfish person\n","\n","\n","Term: \n"," portray\n","Sentence: \n"," \n","\n","\n","Term: \n"," emblem\n","Sentence: \n"," \n","\n","\n","Term: \n"," trichosurus\n","Sentence: \n"," \n","\n","\n","Term: \n"," anthrax\n","Sentence: \n"," \n","\n","\n","Term: \n"," epithet\n","Sentence: \n"," This restaurant changed hands twice last year\n","\n","\n","Term: \n"," change owners\n","Sentence: \n"," \n","\n","\n","Term: \n"," matrimony vine\n","Sentence: \n"," the American colony in Paris\n","\n","\n","Term: \n"," settlement\n","Sentence: \n"," she was humming an air from Beethoven\n","\n","\n","Term: \n"," tune\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus chlorophoneus\n","Sentence: \n"," Do you carry kerosene heaters?\n","\n","\n","Term: \n"," stock\n","Sentence: \n"," She repaired her TV set\n","\n","\n","Term: \n"," fix\n","Sentence: \n"," \n","\n","\n","Term: \n"," perennate\n","Sentence: \n"," \n","\n","\n","Term: \n"," search\n","Sentence: \n"," \n","\n","\n","Term: \n"," legal principle\n","Sentence: \n"," \n","\n","\n","Term: \n"," caloosahatchee river\n","Sentence: \n"," \n","\n","\n","Term: \n"," pterocarpus marsupium\n","Sentence: \n"," \n","\n","\n","Term: \n"," mafia\n","Sentence: \n"," The prisoner writhed in discomfort\n","\n","\n","Term: \n"," twist\n","Sentence: \n"," follow God's light\n","\n","\n","Term: \n"," illumination\n","Sentence: \n"," active tuberculosis\n","\n","\n","Term: \n"," active\n","Sentence: \n"," \n","\n","\n","Term: \n"," sea pea\n","Sentence: \n"," \n","\n","\n","Term: \n"," governor\n","Sentence: \n"," the dollar soared against the yen\n","\n","\n","Term: \n"," soar\n","Sentence: \n"," \n","\n","\n","Term: \n"," concert\n","Sentence: \n"," Don't run--you'll be out of breath\n","\n","\n","Term: \n"," run\n","Sentence: \n"," \n","\n","\n","Term: \n"," diphenylbutyl piperidine\n","Sentence: \n"," \n","\n","\n","Term: \n"," oxyuranus\n","Sentence: \n"," \n","\n","\n","Term: \n"," trigonum cerebrale\n","Sentence: \n"," \n","\n","\n","Term: \n"," remise\n","Sentence: \n"," \n","\n","\n","Term: \n"," mount kanchenjunga\n","Sentence: \n"," \n","\n","\n","Term: \n"," ethanoyl radical\n","Sentence: \n"," \n","\n","\n","Term: \n"," takeoff\n","Sentence: \n"," She was digging away at her math homework\n","\n","\n","Term: \n"," labour\n","Sentence: \n"," The family purchased a new car\n","\n","\n","Term: \n"," buy\n","Sentence: \n"," \n","\n","\n","Term: \n"," unconsciousness\n","Sentence: \n"," the elevator was operated by push buttons\n","\n","\n","Term: \n"," push button\n","Sentence: \n"," \n","\n","\n","Term: \n"," pretermission\n","Sentence: \n"," \n","\n","\n","Term: \n"," oxheart cherry\n","Sentence: \n"," \n","\n","\n","Term: \n"," kissing bug\n","Sentence: \n"," moonlight is the smuggler's enemy\n","\n","\n","Term: \n"," moonshine\n","Sentence: \n"," \n","\n","\n","Term: \n"," squeal\n","Sentence: \n"," \n","\n","\n","Term: \n"," ametropia\n","Sentence: \n"," When you have to hiccup, drink a glass of cold water\n","\n","\n","Term: \n"," hiccup\n","Sentence: \n"," you shouldn't try to start in third gear\n","\n","\n","Term: \n"," third gear\n","Sentence: \n"," \n","\n","\n","Term: \n"," counterrevolutionist\n","Sentence: \n"," \n","\n","\n","Term: \n"," republic of kazakhstan\n","Sentence: \n"," \n","\n","\n","Term: \n"," packer\n","Sentence: \n"," \n","\n","\n","Term: \n"," finance company\n","Sentence: \n"," he is a Palestinian from Gaza\n","\n","\n","Term: \n"," gaza strip\n","Sentence: \n"," \n","\n","\n","Term: \n"," knower\n","Sentence: \n"," \n","\n","\n","Term: \n"," state of kuwait\n","Sentence: \n"," \n","\n","\n","Term: \n"," lates\n","Sentence: \n"," \n","\n","\n","Term: \n"," oligosaccharide\n","Sentence: \n"," \n","\n","\n","Term: \n"," shopper\n","Sentence: \n"," \n","\n","\n","Term: \n"," tanacetum parthenium\n","Sentence: \n"," \n","\n","\n","Term: \n"," expansivity\n","Sentence: \n"," \n","\n","\n","Term: \n"," gymnosophy\n","Sentence: \n"," \n","\n","\n","Term: \n"," deconstructionism\n","Sentence: \n"," \n","\n","\n","Term: \n"," ziziphus jujuba\n","Sentence: \n"," that rule is no longer in operation\n","\n","\n","Term: \n"," operation\n","Sentence: \n"," \n","\n","\n","Term: \n"," rear of tube\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus armeria\n","Sentence: \n"," \n","\n","\n","Term: \n"," kitchen\n","Sentence: \n"," \n","\n","\n","Term: \n"," roy orbison\n","Sentence: \n"," \n","\n","\n","Term: \n"," harmony\n","Sentence: \n"," \n","\n","\n","Term: \n"," paisa\n","Sentence: \n"," Foster our children's well-being and education\n","\n","\n","Term: \n"," further\n","Sentence: \n"," his ad-libs got him in trouble with the politicians\n","\n","\n","Term: \n"," ad-lib\n","Sentence: \n"," \n","\n","\n","Term: \n"," paris\n","Sentence: \n"," \n","\n","\n","Term: \n"," female mammal\n","Sentence: \n"," \n","\n","\n","Term: \n"," ingesta\n","Sentence: \n"," \n","\n","\n","Term: \n"," payee\n","Sentence: \n"," \n","\n","\n","Term: \n"," deaminize\n","Sentence: \n"," \n","\n","\n","Term: \n"," scolopacidae\n","Sentence: \n"," \n","\n","\n","Term: \n"," occultism\n","Sentence: \n"," \n","\n","\n","Term: \n"," nude\n","Sentence: \n"," it was full of rackets, balls and other objects\n","\n","\n","Term: \n"," physical object\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus ascaridia\n","Sentence: \n"," \n","\n","\n","Term: \n"," scaling\n","Sentence: \n"," \n","\n","\n","Term: \n"," kingdom of denmark\n","Sentence: \n"," \n","\n","\n","Term: \n"," zanthoxylum\n","Sentence: \n"," \n","\n","\n","Term: \n"," free phagocyte\n","Sentence: \n"," \n","\n","\n","Term: \n"," vinyl resin\n","Sentence: \n"," \n","\n","\n","Term: \n"," wedding ceremony\n","Sentence: \n"," dull repetitious work gives no gratification\n","\n","\n","Term: \n"," gratification\n","Sentence: \n"," \n","\n","\n","Term: \n"," blenheim\n","Sentence: \n"," a high temperature\n","\n","\n","Term: \n"," high\n","Sentence: \n"," \n","\n","\n","Term: \n"," glutethimide\n","Sentence: \n"," \n","\n","\n","Term: \n"," zip code\n","Sentence: \n"," The tree stump serves as a table\n","\n","\n","Term: \n"," serve\n","Sentence: \n"," \n","\n","\n","Term: \n"," lefteyed flounder\n","Sentence: \n"," \n","\n","\n","Term: \n"," general\n","Sentence: \n"," \n","\n","\n","Term: \n"," enforcement\n","Sentence: \n"," \n","\n","\n","Term: \n"," software error\n","Sentence: \n"," \n","\n","\n","Term: \n"," farmerette\n","Sentence: \n"," \n","\n","\n","Term: \n"," hoop ash\n","Sentence: \n"," \n","\n","\n","Term: \n"," vocal\n","Sentence: \n"," \n","\n","\n","Term: \n"," fell\n","Sentence: \n"," \n","\n","\n","Term: \n"," income tax\n","Sentence: \n"," \n","\n","\n","Term: \n"," liquidness\n","Sentence: \n"," \n","\n","\n","Term: \n"," kaury\n","Sentence: \n"," \n","\n","\n","Term: \n"," claforan\n","Sentence: \n"," a slow walker\n","\n","\n","Term: \n"," slow\n","Sentence: \n"," pulverize the grains\n","\n","\n","Term: \n"," pulverize\n","Sentence: \n"," suppress a nascent uprising\n","\n","\n","Term: \n"," suppress\n","Sentence: \n"," \n","\n","\n","Term: \n"," st. jerome\n","Sentence: \n"," \n","\n","\n","Term: \n"," placeseeker\n","Sentence: \n"," \n","\n","\n","Term: \n"," order bryales\n","Sentence: \n"," \n","\n","\n","Term: \n"," redcap\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus calidris\n","Sentence: \n"," \n","\n","\n","Term: \n"," seed vessel\n","Sentence: \n"," \n","\n","\n","Term: \n"," thatcherism\n","Sentence: \n"," The teacher often flogged the students\n","\n","\n","Term: \n"," lather\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus agave\n","Sentence: \n"," \n","\n","\n","Term: \n"," straddle\n","Sentence: \n"," He grimaced when he saw the amount of homework he had to do\n","\n","\n","Term: \n"," pull a face\n","Sentence: \n"," \n","\n","\n","Term: \n"," lupus\n","Sentence: \n"," \n","\n","\n","Term: \n"," scrotum\n","Sentence: \n"," \n","\n","\n","Term: \n"," thecodontia\n","Sentence: \n"," \n","\n","\n","Term: \n"," pterygoid process\n","Sentence: \n"," \n","\n","\n","Term: \n"," countermine\n","Sentence: \n"," The cold water quenched his thirst\n","\n","\n","Term: \n"," quench\n","Sentence: \n"," \n","\n","\n","Term: \n"," taxidermist\n","Sentence: \n"," \n","\n","\n","Term: \n"," psychological disorder\n","Sentence: \n"," The mayor tried to humanize life in the big city\n","\n","\n","Term: \n"," humanize\n","Sentence: \n"," \n","\n","\n","Term: \n"," talien\n","Sentence: \n"," the entrance was guarded by ranks of policemen\n","\n","\n","Term: \n"," rank\n","Sentence: \n"," \n","\n","\n","Term: \n"," deliveryman\n","Sentence: \n"," \n","\n","\n","Term: \n"," pterodactylidae\n","Sentence: \n"," the volcano erupted after centuries of dormancy\n","\n","\n","Term: \n"," quiescency\n","Sentence: \n"," \n","\n","\n","Term: \n"," whip-round\n","Sentence: \n"," \n","\n","\n","Term: \n"," stunt\n","Sentence: \n"," \n","\n","\n","Term: \n"," psychotherapist\n","Sentence: \n"," \n","\n","\n","Term: \n"," tswana\n","Sentence: \n"," \n","\n","\n","Term: \n"," new zealand\n","Sentence: \n"," \n","\n","\n","Term: \n"," omelette\n","Sentence: \n"," let's postpone the exam\n","\n","\n","Term: \n"," put off\n","Sentence: \n"," \n","\n","\n","Term: \n"," big board\n","Sentence: \n"," \n","\n","\n","Term: \n"," ecosoc commission\n","Sentence: \n"," \n","\n","\n","Term: \n"," pseudoscorpion\n","Sentence: \n"," \n","\n","\n","Term: \n"," dispenser\n","Sentence: \n"," events suddenly took an awkward turn\n","\n","\n","Term: \n"," twist\n","Sentence: \n"," I cannot accept the dogma of this church\n","\n","\n","Term: \n"," accept\n","Sentence: \n"," \n","\n","\n","Term: \n"," sporobolus poiretii\n","Sentence: \n"," \n","\n","\n","Term: \n"," family chalcididae\n","Sentence: \n"," \n","\n","\n","Term: \n"," recapitulation\n","Sentence: \n"," The family took off for Florida\n","\n","\n","Term: \n"," take off\n","Sentence: \n"," \n","\n","\n","Term: \n"," federal agent\n","Sentence: \n"," \n","\n","\n","Term: \n"," whisper\n","Sentence: \n"," \n","\n","\n","Term: \n"," ticket\n","Sentence: \n"," the majority of Iraqi are Arab Shiite Muslims although Sunni Muslims control the government\n","\n","\n","Term: \n"," iraqi\n","Sentence: \n"," \n","\n","\n","Term: \n"," upgrade\n","Sentence: \n"," \n","\n","\n","Term: \n"," ohmage\n","Sentence: \n"," \n","\n","\n","Term: \n"," thick-knee\n","Sentence: \n"," \n","\n","\n","Term: \n"," broccoli\n","Sentence: \n"," The chemist evaporated the water\n","\n","\n","Term: \n"," vaporise\n","Sentence: \n"," he spoke in broad generalities\n","\n","\n","Term: \n"," generality\n","Sentence: \n"," \n","\n","\n","Term: \n"," ltd.\n","Sentence: \n"," \n","\n","\n","Term: \n"," tritoma\n","Sentence: \n"," genic combinations\n","\n","\n","Term: \n"," genetical\n","Sentence: \n"," \n","\n","\n","Term: \n"," lucas\n","Sentence: \n"," \n","\n","\n","Term: \n"," quail\n","Sentence: \n"," an idea comprehensible to the average mind\n","\n","\n","Term: \n"," comprehensible\n","Sentence: \n"," \n","\n","\n","Term: \n"," taps\n","Sentence: \n"," the hospital has an excellent nursing staff\n","\n","\n","Term: \n"," staff\n","Sentence: \n"," he looked the other direction\n","\n","\n","Term: \n"," direction\n","Sentence: \n"," Someone tampered with the documents on my desk\n","\n","\n","Term: \n"," tamper\n","Sentence: \n"," \n","\n","\n","Term: \n"," vulcanizer\n","Sentence: \n"," \n","\n","\n","Term: \n"," designer\n","Sentence: \n"," She composed a poem\n","\n","\n","Term: \n"," write\n","Sentence: \n"," \n","\n","\n","Term: \n"," lacer\n","Sentence: \n"," \n","\n","\n","Term: \n"," gesture\n","Sentence: \n"," \n","\n","\n","Term: \n"," bird cherry tree\n","Sentence: \n"," \n","\n","\n","Term: \n"," signalman\n","Sentence: \n"," \n","\n","\n","Term: \n"," plaint\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus erignathus\n","Sentence: \n"," \n","\n","\n","Term: \n"," quick assets\n","Sentence: \n"," he had a sparkle in his eye\n","\n","\n","Term: \n"," sparkle\n","Sentence: \n"," \n","\n","\n","Term: \n"," tanacetum\n","Sentence: \n"," \n","\n","\n","Term: \n"," writer\n","Sentence: \n"," he collected dry sticks for a campfire\n","\n","\n","Term: \n"," stick\n","Sentence: \n"," People wanted to stone the woman who had a child out of wedlock\n","\n","\n","Term: \n"," stone\n","Sentence: \n"," \n","\n","\n","Term: \n"," work unit\n","Sentence: \n"," \n","\n","\n","Term: \n"," out-of-the-box thinking\n","Sentence: \n"," \n","\n","\n","Term: \n"," order cordaitales\n","Sentence: \n"," \n","\n","\n","Term: \n"," foreign aid\n","Sentence: \n"," \n","\n","\n","Term: \n"," devaluation\n","Sentence: \n"," \n","\n","\n","Term: \n"," quarryman\n","Sentence: \n"," \n","\n","\n","Term: \n"," mistflower\n","Sentence: \n"," \n","\n","\n","Term: \n"," auctioneer\n","Sentence: \n"," \n","\n","\n","Term: \n"," levant\n","Sentence: \n"," \n","\n","\n","Term: \n"," waters\n","Sentence: \n"," \n","\n","\n","Term: \n"," hop\n","Sentence: \n"," \n","\n","\n","Term: \n"," star\n","Sentence: \n"," obviously bemused by his questions\n","\n","\n","Term: \n"," confused\n","Sentence: \n"," \n","\n","\n","Term: \n"," rubiales\n","Sentence: \n"," \n","\n","\n","Term: \n"," drag\n","Sentence: \n"," subsequent developments\n","\n","\n","Term: \n"," subsequent\n","Sentence: \n"," \n","\n","\n","Term: \n"," troglodytes\n","Sentence: \n"," \n","\n","\n","Term: \n"," dance\n","Sentence: \n"," it took two strokes to get out of the bunker\n","\n","\n","Term: \n"," stroke\n","Sentence: \n"," \n","\n","\n","Term: \n"," trevino\n","Sentence: \n"," \n","\n","\n","Term: \n"," king of the germans\n","Sentence: \n"," \n","\n","\n","Term: \n"," porousness\n","Sentence: \n"," things happen in the earth and sky with no discernible cause\n","\n","\n","Term: \n"," discernible\n","Sentence: \n"," \n","\n","\n","Term: \n"," b-52\n","Sentence: \n"," \n","\n","\n","Term: \n"," john bunyan\n","Sentence: \n"," \n","\n","\n","Term: \n"," spiny anteater\n","Sentence: \n"," \n","\n","\n","Term: \n"," stooge\n","Sentence: \n"," \n","\n","\n","Term: \n"," sauce\n","Sentence: \n"," \n","\n","\n","Term: \n"," centrifugation\n","Sentence: \n"," \n","\n","\n","Term: \n"," superorder ratitae\n","Sentence: \n"," the long repression of Christian sects\n","\n","\n","Term: \n"," repression\n","Sentence: \n"," \n","\n","\n","Term: \n"," rhizobiaceae\n","Sentence: \n"," \n","\n","\n","Term: \n"," cyst\n","Sentence: \n"," \n","\n","\n","Term: \n"," constriction\n","Sentence: \n"," \n","\n","\n","Term: \n"," commandery\n","Sentence: \n"," \n","\n","\n","Term: \n"," diesel locomotive\n","Sentence: \n"," \n","\n","\n","Term: \n"," nanus\n","Sentence: \n"," The dress remained wet after repeated attempts to dry it\n","\n","\n","Term: \n"," stay\n","Sentence: \n"," \n","\n","\n","Term: \n"," spittlebug\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus andira\n","Sentence: \n"," \n","\n","\n","Term: \n"," backbencher\n","Sentence: \n"," he tested for the presence of radon\n","\n","\n","Term: \n"," presence\n","Sentence: \n"," \n","\n","\n","Term: \n"," pouch\n","Sentence: \n"," the state has elected a new president\n","\n","\n","Term: \n"," country\n","Sentence: \n"," \n","\n","\n","Term: \n"," teuton\n","Sentence: \n"," \n","\n","\n","Term: \n"," neglect\n","Sentence: \n"," \n","\n","\n","Term: \n"," unicycle\n","Sentence: \n"," \n","\n","\n","Term: \n"," mortise\n","Sentence: \n"," \n","\n","\n","Term: \n"," suborder lari\n","Sentence: \n"," \n","\n","\n","Term: \n"," tumulus\n","Sentence: \n"," \n","\n","\n","Term: \n"," torrent\n","Sentence: \n"," \n","\n","\n","Term: \n"," striped maple\n","Sentence: \n"," \n","\n","\n","Term: \n"," sideboard\n","Sentence: \n"," The laundry dries in the sun\n","\n","\n","Term: \n"," dry out\n","Sentence: \n"," \n","\n","\n","Term: \n"," otus\n","Sentence: \n"," \n","\n","\n","Term: \n"," thoracic cavity\n","Sentence: \n"," \n","\n","\n","Term: \n"," upbringing\n","Sentence: \n"," \n","\n","\n","Term: \n"," water witch\n","Sentence: \n"," \n","\n","\n","Term: \n"," horseman\n","Sentence: \n"," \n","\n","\n","Term: \n"," lapidary\n","Sentence: \n"," \n","\n","\n","Term: \n"," holdup\n","Sentence: \n"," They processed into the dining room\n","\n","\n","Term: \n"," march\n","Sentence: \n"," \n","\n","\n","Term: \n"," crossbencher\n","Sentence: \n"," \n","\n","\n","Term: \n"," hebrew\n","Sentence: \n"," as he heard the news he was suddenly flooded with relief\n","\n","\n","Term: \n"," relief\n","Sentence: \n"," \n","\n","\n","Term: \n"," coricidin\n","Sentence: \n"," \n","\n","\n","Term: \n"," boldface\n","Sentence: \n"," She died from cancer\n","\n","\n","Term: \n"," die\n","Sentence: \n"," \n","\n","\n","Term: \n"," monitoring device\n","Sentence: \n"," He peeped at the woman through the window\n","\n","\n","Term: \n"," peep\n","Sentence: \n"," \n","\n","\n","Term: \n"," pithecellodium unguis-cati\n","Sentence: \n"," \n","\n","\n","Term: \n"," sialis\n","Sentence: \n"," \n","\n","\n","Term: \n"," tongue-lashing\n","Sentence: \n"," Don't trespass on my land!\n","\n","\n","Term: \n"," trespass\n","Sentence: \n"," We are remodeling these rooms\n","\n","\n","Term: \n"," remodel\n","Sentence: \n"," \n","\n","\n","Term: \n"," lake tahoe\n","Sentence: \n"," \n","\n","\n","Term: \n"," rudbeckia\n","Sentence: \n"," \n","\n","\n","Term: \n"," platitude\n","Sentence: \n"," \n","\n","\n","Term: \n"," axiom\n","Sentence: \n"," zap the enemy\n","\n","\n","Term: \n"," nuke\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus borassus\n","Sentence: \n"," He palavered her into going along\n","\n","\n","Term: \n"," wheedle\n","Sentence: \n"," \n","\n","\n","Term: \n"," tenderization\n","Sentence: \n"," \n","\n","\n","Term: \n"," roll down\n","Sentence: \n"," \n","\n","\n","Term: \n"," topmast\n","Sentence: \n"," The words are misapplied in this context\n","\n","\n","Term: \n"," misuse\n","Sentence: \n"," he angled his way into the room\n","\n","\n","Term: \n"," angle\n","Sentence: \n"," \n","\n","\n","Term: \n"," stays\n","Sentence: \n"," \n","\n","\n","Term: \n"," sparaxis\n","Sentence: \n"," Who is overseeing this project?\n","\n","\n","Term: \n"," supervise\n","Sentence: \n"," \n","\n","\n","Term: \n"," paralithodes camtschatica\n","Sentence: \n"," \n","\n","\n","Term: \n"," augean stables\n","Sentence: \n"," return to sender\n","\n","\n","Term: \n"," transmitter\n","Sentence: \n"," \n","\n","\n","Term: \n"," consumerism\n","Sentence: \n"," \n","\n","\n","Term: \n"," spirit\n","Sentence: \n"," the sting of death\n","\n","\n","Term: \n"," sting\n","Sentence: \n"," The President aberrated from being a perfect gentleman\n","\n","\n","Term: \n"," aberrate\n","Sentence: \n"," \n","\n","\n","Term: \n"," ebonics\n","Sentence: \n"," \n","\n","\n","Term: \n"," neurogenesis\n","Sentence: \n"," The road widened\n","\n","\n","Term: \n"," widen\n","Sentence: \n"," we watch the 7 o'clock news every night\n","\n","\n","Term: \n"," news show\n","Sentence: \n"," \n","\n","\n","Term: \n"," demarcate\n","Sentence: \n"," \n","\n","\n","Term: \n"," parade\n","Sentence: \n"," \n","\n","\n","Term: \n"," right of first publication\n","Sentence: \n"," \n","\n","\n","Term: \n"," renting\n","Sentence: \n"," \n","\n","\n","Term: \n"," squatinidae\n","Sentence: \n"," the untroubled kingdom of reason\n","\n","\n","Term: \n"," kingdom\n","Sentence: \n"," \n","\n","\n","Term: \n"," unrepentant\n","Sentence: \n"," \n","\n","\n","Term: \n"," swivel\n","Sentence: \n"," \n","\n","\n","Term: \n"," submersible\n","Sentence: \n"," \n","\n","\n","Term: \n"," nasturtium\n","Sentence: \n"," \n","\n","\n","Term: \n"," projection\n","Sentence: \n"," check the brakes\n","\n","\n","Term: \n"," suss out\n","Sentence: \n"," \n","\n","\n","Term: \n"," pagophila eburnea\n","Sentence: \n"," He sank to his knees\n","\n","\n","Term: \n"," sink\n","Sentence: \n"," \n","\n","\n","Term: \n"," subdivision\n","Sentence: \n"," point a chimney\n","\n","\n","Term: \n"," repoint\n","Sentence: \n"," \n","\n","\n","Term: \n"," gothic\n","Sentence: \n"," \n","\n","\n","Term: \n"," soleirolia soleirolii\n","Sentence: \n"," \n","\n","\n","Term: \n"," shootout\n","Sentence: \n"," \n","\n","\n","Term: \n"," swift\n","Sentence: \n"," \n","\n","\n","Term: \n"," pisces\n","Sentence: \n"," He edged towards the car\n","\n","\n","Term: \n"," inch\n","Sentence: \n"," \n","\n","\n","Term: \n"," paulo afonso falls\n","Sentence: \n"," \n","\n","\n","Term: \n"," mao zedong\n","Sentence: \n"," \n","\n","\n","Term: \n"," scrutinizer\n","Sentence: \n"," Every star seemed to flare with new intensity\n","\n","\n","Term: \n"," flare\n","Sentence: \n"," \n","\n","\n","Term: \n"," melanerpes\n","Sentence: \n"," social groups form everywhere\n","\n","\n","Term: \n"," organize\n","Sentence: \n"," \n","\n","\n","Term: \n"," australian state\n","Sentence: \n"," \n","\n","\n","Term: \n"," channelization\n","Sentence: \n"," it was the opening session of the legislature\n","\n","\n","Term: \n"," session\n","Sentence: \n"," His eyes brimmed with tears\n","\n","\n","Term: \n"," brim\n","Sentence: \n"," \n","\n","\n","Term: \n"," rumen\n","Sentence: \n"," \n","\n","\n","Term: \n"," turner\n","Sentence: \n"," \n","\n","\n","Term: \n"," jungle fowl\n","Sentence: \n"," \n","\n","\n","Term: \n"," seigniory\n","Sentence: \n"," \n","\n","\n","Term: \n"," editorialize\n","Sentence: \n"," \n","\n","\n","Term: \n"," astrocyte\n","Sentence: \n"," His eyes popped\n","\n","\n","Term: \n"," pop\n","Sentence: \n"," \n","\n","\n","Term: \n"," kirkia\n","Sentence: \n"," \n","\n","\n","Term: \n"," papilionaceae\n","Sentence: \n"," a blueprint for a house\n","\n","\n","Term: \n"," blueprint\n","Sentence: \n"," She felt resentful\n","\n","\n","Term: \n"," feel\n","Sentence: \n"," \n","\n","\n","Term: \n"," thrift\n","Sentence: \n"," he had a sparkle in his eye\n","\n","\n","Term: \n"," sparkle\n","Sentence: \n"," she lives on welfare\n","\n","\n","Term: \n"," welfare\n","Sentence: \n"," \n","\n","\n","Term: \n"," john hemminge\n","Sentence: \n"," \n","\n","\n","Term: \n"," shop boy\n","Sentence: \n"," \n","\n","\n","Term: \n"," elephant\n","Sentence: \n"," \n","\n","\n","Term: \n"," gulping\n","Sentence: \n"," She didn't want to answer\n","\n","\n","Term: \n"," answer\n","Sentence: \n"," \n","\n","\n","Term: \n"," sir james murray\n","Sentence: \n"," \n","\n","\n","Term: \n"," leaflet\n","Sentence: \n"," \n","\n","\n","Term: \n"," loop\n","Sentence: \n"," \n","\n","\n","Term: \n"," preemption\n","Sentence: \n"," \n","\n","\n","Term: \n"," trading operations\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus chlamyphorus\n","Sentence: \n"," a grain of sand\n","\n","\n","Term: \n"," grain\n","Sentence: \n"," \n","\n","\n","Term: \n"," backplate\n","Sentence: \n"," a channel is typically what you rent from a telephone company\n","\n","\n","Term: \n"," channel\n","Sentence: \n"," \n","\n","\n","Term: \n"," freshwater\n","Sentence: \n"," \n","\n","\n","Term: \n"," yellow rocket\n","Sentence: \n"," \n","\n","\n","Term: \n"," loose cannon\n","Sentence: \n"," \n","\n","\n","Term: \n"," clothes moth\n","Sentence: \n"," \n","\n","\n","Term: \n"," water bug\n","Sentence: \n"," \n","\n","\n","Term: \n"," numbat\n","Sentence: \n"," \n","\n","\n","Term: \n"," principality\n","Sentence: \n"," \n","\n","\n","Term: \n"," sabah\n","Sentence: \n"," the stopping point of each round was signaled by a bell\n","\n","\n","Term: \n"," stopping point\n","Sentence: \n"," \n","\n","\n","Term: \n"," purvey\n","Sentence: \n"," \n","\n","\n","Term: \n"," warhorse\n","Sentence: \n"," We began working at dawn\n","\n","\n","Term: \n"," begin\n","Sentence: \n"," \n","\n","\n","Term: \n"," tongue\n","Sentence: \n"," I'll probably see you at the meeting\n","\n","\n","Term: \n"," meet\n","Sentence: \n"," a pretentious country house\n","\n","\n","Term: \n"," pretentious\n","Sentence: \n"," \n","\n","\n","Term: \n"," sea holm\n","Sentence: \n"," she could hear echoes of her own footsteps\n","\n","\n","Term: \n"," sound reflection\n","Sentence: \n"," \n","\n","\n","Term: \n"," stigmatization\n","Sentence: \n"," \n","\n","\n","Term: \n"," grandpa\n","Sentence: \n"," it was their habit to dine at 7 every evening\n","\n","\n","Term: \n"," habit\n","Sentence: \n"," \n","\n","\n","Term: \n"," tayassu tajacu\n","Sentence: \n"," \n","\n","\n","Term: \n"," trichys\n","Sentence: \n"," \n","\n","\n","Term: \n"," streetwalker\n","Sentence: \n"," \n","\n","\n","Term: \n"," water plant\n","Sentence: \n"," a complex set of variations based on a simple folk melody\n","\n","\n","Term: \n"," complex\n","Sentence: \n"," \n","\n","\n","Term: \n"," enjoyment\n","Sentence: \n"," \n","\n","\n","Term: \n"," suborder sciuromorpha\n","Sentence: \n"," \n","\n","\n","Term: \n"," sten gun\n","Sentence: \n"," \n","\n","\n","Term: \n"," java\n","Sentence: \n"," \n","\n","\n","Term: \n"," musculature\n","Sentence: \n"," \n","\n","\n","Term: \n"," sliver\n","Sentence: \n"," \n","\n","\n","Term: \n"," two-dimensional figure\n","Sentence: \n"," \n","\n","\n","Term: \n"," plughole\n","Sentence: \n"," \n","\n","\n","Term: \n"," salix tristis\n","Sentence: \n"," The child yawned during the long performance\n","\n","\n","Term: \n"," yawn\n","Sentence: \n"," \n","\n","\n","Term: \n"," isoetes\n","Sentence: \n"," \n","\n","\n","Term: \n"," todea superba\n","Sentence: \n"," \n","\n","\n","Term: \n"," sea kale\n","Sentence: \n"," the car couldn't make it up the rise\n","\n","\n","Term: \n"," upgrade\n","Sentence: \n"," \n","\n","\n","Term: \n"," sensualize\n","Sentence: \n"," \n","\n","\n","Term: \n"," duckweed\n","Sentence: \n"," \n","\n","\n","Term: \n"," prelature\n","Sentence: \n"," \n","\n","\n","Term: \n"," unguis\n","Sentence: \n"," crush an aluminum can\n","\n","\n","Term: \n"," squeeze\n","Sentence: \n"," \n","\n","\n","Term: \n"," prong\n","Sentence: \n"," I cashed the check as soon as it arrived in the mail\n","\n","\n","Term: \n"," cash in\n","Sentence: \n"," \n","\n","\n","Term: \n"," flit\n","Sentence: \n"," \n","\n","\n","Term: \n"," spare tire\n","Sentence: \n"," hunger had caused the hollows in their cheeks\n","\n","\n","Term: \n"," hollow\n","Sentence: \n"," \n","\n","\n","Term: \n"," dipylon gate\n","Sentence: \n"," \n","\n","\n","Term: \n"," rubia\n","Sentence: \n"," rubberize fabric for rain coats\n","\n","\n","Term: \n"," rubberize\n","Sentence: \n"," \n","\n","\n","Term: \n"," yellow mountain saxifrage\n","Sentence: \n"," This student sleeps with everyone in her dorm\n","\n","\n","Term: \n"," screw\n","Sentence: \n"," \n","\n","\n","Term: \n"," incurvature\n","Sentence: \n"," \n","\n","\n","Term: \n"," card player\n","Sentence: \n"," cover her face with a handkerchief\n","\n","\n","Term: \n"," cover\n","Sentence: \n"," between two consonants, this liquid is vowelized\n","\n","\n","Term: \n"," vowelize\n","Sentence: \n"," the compressed gas exerts an increased pressure\n","\n","\n","Term: \n"," pressure\n","Sentence: \n"," \n","\n","\n","Term: \n"," swag\n","Sentence: \n"," \n","\n","\n","Term: \n"," free association\n","Sentence: \n"," they played the adagio too quickly\n","\n","\n","Term: \n"," adagio\n","Sentence: \n"," \n","\n","\n","Term: \n"," sieve\n","Sentence: \n"," \n","\n","\n","Term: \n"," israeli\n","Sentence: \n"," \n","\n","\n","Term: \n"," woolgather\n","Sentence: \n"," \n","\n","\n","Term: \n"," mentholated salve\n","Sentence: \n"," \n","\n","\n","Term: \n"," moveable feast\n","Sentence: \n"," Things that die with their eyes open and questing\n","\n","\n","Term: \n"," quest\n","Sentence: \n"," \n","\n","\n","Term: \n"," virginian sumac\n","Sentence: \n"," \n","\n","\n","Term: \n"," true guava\n","Sentence: \n"," \n","\n","\n","Term: \n"," procyonidae\n","Sentence: \n"," \n","\n","\n","Term: \n"," sarcoma\n","Sentence: \n"," \n","\n","\n","Term: \n"," yottabyte\n","Sentence: \n"," \n","\n","\n","Term: \n"," order ephemeroptera\n","Sentence: \n"," \n","\n","\n","Term: \n"," sir charles spencer chaplin\n","Sentence: \n"," \n","\n","\n","Term: \n"," stinger\n","Sentence: \n"," \n","\n","\n","Term: \n"," mule\n","Sentence: \n"," \n","\n","\n","Term: \n"," winter squash plant\n","Sentence: \n"," with the help of his friend's interpolations his story was eventually told\n","\n","\n","Term: \n"," interpolation\n","Sentence: \n"," \n","\n","\n","Term: \n"," bus service\n","Sentence: \n"," \n","\n","\n","Term: \n"," insectivore\n","Sentence: \n"," \n","\n","\n","Term: \n"," white person\n","Sentence: \n"," a nice line of shoes\n","\n","\n","Term: \n"," product line\n","Sentence: \n"," \n","\n","\n","Term: \n"," orthodontist\n","Sentence: \n"," \n","\n","\n","Term: \n"," sharpy\n","Sentence: \n"," \n","\n","\n","Term: \n"," pedagogue\n","Sentence: \n"," \n","\n","\n","Term: \n"," sayornis phoebe\n","Sentence: \n"," Close the door\n","\n","\n","Term: \n"," shut\n","Sentence: \n"," several of the details are similar\n","\n","\n","Term: \n"," detail\n","Sentence: \n"," \n","\n","\n","Term: \n"," addressee\n","Sentence: \n"," \n","\n","\n","Term: \n"," dihybrid cross\n","Sentence: \n"," \n","\n","\n","Term: \n"," pontederia\n","Sentence: \n"," a contract advantageous to our country\n","\n","\n","Term: \n"," advantageous\n","Sentence: \n"," \n","\n","\n","Term: \n"," sedative-hypnotic drug\n","Sentence: \n"," \n","\n","\n","Term: \n"," cinematographer\n","Sentence: \n"," \n","\n","\n","Term: \n"," repartee\n","Sentence: \n"," \n","\n","\n","Term: \n"," court game\n","Sentence: \n"," \n","\n","\n","Term: \n"," reproduction\n","Sentence: \n"," \n","\n","\n","Term: \n"," butchery\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus aralia\n","Sentence: \n"," that rule is no longer in operation\n","\n","\n","Term: \n"," operation\n","Sentence: \n"," \n","\n","\n","Term: \n"," towrope\n","Sentence: \n"," How could I miss that typo?\n","\n","\n","Term: \n"," neglect\n","Sentence: \n"," they used face recognition to spot known terrorists\n","\n","\n","Term: \n"," facial recognition\n","Sentence: \n"," budget separately for goods and services\n","\n","\n","Term: \n"," service\n","Sentence: \n"," \n","\n","\n","Term: \n"," metalworks\n","Sentence: \n"," \n","\n","\n","Term: \n"," cooperstown\n","Sentence: \n"," \n","\n","\n","Term: \n"," sign off\n","Sentence: \n"," \n","\n","\n","Term: \n"," perching bird\n","Sentence: \n"," \n","\n","\n","Term: \n"," module\n","Sentence: \n"," \n","\n","\n","Term: \n"," provincial capital\n","Sentence: \n"," in inflation everything gets more valuable except money\n","\n","\n","Term: \n"," rising prices\n","Sentence: \n"," The well was spudded in April\n","\n","\n","Term: \n"," spud\n","Sentence: \n"," Muscles that are not used will atrophy\n","\n","\n","Term: \n"," atrophy\n","Sentence: \n"," the race for the presidency\n","\n","\n","Term: \n"," race\n","Sentence: \n"," \n","\n","\n","Term: \n"," judaism\n","Sentence: \n"," \n","\n","\n","Term: \n"," navigation\n","Sentence: \n"," \n","\n","\n","Term: \n"," cimarron river\n","Sentence: \n"," the telephone installation took only a few minutes\n","\n","\n","Term: \n"," installation\n","Sentence: \n"," \n","\n","\n","Term: \n"," mortuary\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus arctonyx\n","Sentence: \n"," \n","\n","\n","Term: \n"," cardiac arrhythmia\n","Sentence: \n"," glass in a porch\n","\n","\n","Term: \n"," glass in\n","Sentence: \n"," \n","\n","\n","Term: \n"," petunia\n","Sentence: \n"," The enemy withdrew\n","\n","\n","Term: \n"," withdraw\n","Sentence: \n"," \n","\n","\n","Term: \n"," jovian planet\n","Sentence: \n"," \n","\n","\n","Term: \n"," pyrocephalus\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus delairea\n","Sentence: \n"," The bank demanded payment of the loan\n","\n","\n","Term: \n"," exact\n","Sentence: \n"," pizza has too much fat\n","\n","\n","Term: \n"," fat\n","Sentence: \n"," according to his statement he was in London on that day\n","\n","\n","Term: \n"," statement\n","Sentence: \n"," \n","\n","\n","Term: \n"," woolgathering\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus luffa\n","Sentence: \n"," sigeh legally wraps premarital sex in an Islamic cloak\n","\n","\n","Term: \n"," sigeh\n","Sentence: \n"," \n","\n","\n","Term: \n"," queerness\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus chrysemys\n","Sentence: \n"," \n","\n","\n","Term: \n"," tranquillity\n","Sentence: \n"," \n","\n","\n","Term: \n"," taiwanese\n","Sentence: \n"," \n","\n","\n","Term: \n"," sofa\n","Sentence: \n"," \n","\n","\n","Term: \n"," rheum\n","Sentence: \n"," \n","\n","\n","Term: \n"," anchorperson\n","Sentence: \n"," \n","\n","\n","Term: \n"," ensign\n","Sentence: \n"," the schools comply with federal standards\n","\n","\n","Term: \n"," standard\n","Sentence: \n"," the wrench to his knee occurred as he fell\n","\n","\n","Term: \n"," wrench\n","Sentence: \n"," The boards fit neatly\n","\n","\n","Term: \n"," joint\n","Sentence: \n"," Horses used to tow barges along the canal\n","\n","\n","Term: \n"," tow\n","Sentence: \n"," \n","\n","\n","Term: \n"," save\n","Sentence: \n"," \n","\n","\n","Term: \n"," meteorologist\n","Sentence: \n"," his lids would stay open no longer\n","\n","\n","Term: \n"," lid\n","Sentence: \n"," Let us say that he did not tell the truth\n","\n","\n","Term: \n"," suppose\n","Sentence: \n"," \n","\n","\n","Term: \n"," gestation period\n","Sentence: \n"," \n","\n","\n","Term: \n"," link\n","Sentence: \n"," \n","\n","\n","Term: \n"," masochist\n","Sentence: \n"," \n","\n","\n","Term: \n"," characin fish\n","Sentence: \n"," The soldiers fanned out\n","\n","\n","Term: \n"," spread out\n","Sentence: \n"," \n","\n","\n","Term: \n"," truckling\n","Sentence: \n"," \n","\n","\n","Term: \n"," table napkin\n","Sentence: \n"," the disarmament of the aggressor nations must be complete\n","\n","\n","Term: \n"," disarming\n","Sentence: \n"," \n","\n","\n","Term: \n"," inventor\n","Sentence: \n"," her voice is superbly disciplined\n","\n","\n","Term: \n"," wondrously\n","Sentence: \n"," thematic vowels are part of the stem\n","\n","\n","Term: \n"," stem\n","Sentence: \n"," gave false testimony under oath\n","\n","\n","Term: \n"," false\n","Sentence: \n"," He is implicated in the scheme to defraud the government\n","\n","\n","Term: \n"," implicate\n","Sentence: \n"," \n","\n","\n","Term: \n"," goldthread\n","Sentence: \n"," \n","\n","\n","Term: \n"," sarajevo\n","Sentence: \n"," \n","\n","\n","Term: \n"," taximan\n","Sentence: \n"," \n","\n","\n","Term: \n"," clarinet\n","Sentence: \n"," \n","\n","\n","Term: \n"," minimum\n","Sentence: \n"," They conspired to overthrow the government\n","\n","\n","Term: \n"," conspire\n","Sentence: \n"," He joined the Communist Party as a young man\n","\n","\n","Term: \n"," join\n","Sentence: \n"," \n","\n","\n","Term: \n"," levy\n","Sentence: \n"," The chimney exhales a thick smoke\n","\n","\n","Term: \n"," give forth\n","Sentence: \n"," \n","\n","\n","Term: \n"," carbonate\n","Sentence: \n"," \n","\n","\n","Term: \n"," ignition system\n","Sentence: \n"," You should spell out your demands\n","\n","\n","Term: \n"," spell out\n","Sentence: \n"," \n","\n","\n","Term: \n"," statistical regression\n","Sentence: \n"," \n","\n","\n","Term: \n"," hominoid\n","Sentence: \n"," he used a piece of tape for a belt\n","\n","\n","Term: \n"," tape\n","Sentence: \n"," \n","\n","\n","Term: \n"," swampy beggar-ticks\n","Sentence: \n"," \n","\n","\n","Term: \n"," public office\n","Sentence: \n"," \n","\n","\n","Term: \n"," dog days\n","Sentence: \n"," \n","\n","\n","Term: \n"," starch\n","Sentence: \n"," The news really surprised me\n","\n","\n","Term: \n"," surprise\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus crescentia\n","Sentence: \n"," \n","\n","\n","Term: \n"," mutamycin\n","Sentence: \n"," \n","\n","\n","Term: \n"," phytelephas\n","Sentence: \n"," there would be men guarding the horses\n","\n","\n","Term: \n"," guard\n","Sentence: \n"," \n","\n","\n","Term: \n"," lake leman\n","Sentence: \n"," \n","\n","\n","Term: \n"," kolkata\n","Sentence: \n"," \n","\n","\n","Term: \n"," algometry\n","Sentence: \n"," experience often determines ability\n","\n","\n","Term: \n"," shape\n","Sentence: \n"," The drunken men were cursing loudly in the street\n","\n","\n","Term: \n"," swear\n","Sentence: \n"," \n","\n","\n","Term: \n"," sir arthur travers harris\n","Sentence: \n"," \n","\n","\n","Term: \n"," lagos\n","Sentence: \n"," there were distinguishing disfigurements on the suspect's back\n","\n","\n","Term: \n"," disfigurement\n","Sentence: \n"," \n","\n","\n","Term: \n"," red amaranth\n","Sentence: \n"," \n","\n","\n","Term: \n"," pulmonary artery\n","Sentence: \n"," \n","\n","\n","Term: \n"," monogynist\n","Sentence: \n"," loneliness tore through him...whenever he thought of...even the compromising Louis du Tillet\n","\n","\n","Term: \n"," conciliatory\n","Sentence: \n"," \n","\n","\n","Term: \n"," napoli\n","Sentence: \n"," maintained a constant temperature\n","\n","\n","Term: \n"," unvarying\n","Sentence: \n"," I think he is very smart\n","\n","\n","Term: \n"," think\n","Sentence: \n"," \n","\n","\n","Term: \n"," genus chloroxylon\n","Sentence: \n"," \n","\n","\n","Term: \n"," tribe bubalus\n","Sentence: \n"," \n","\n","\n","Term: \n"," melophagus\n","Sentence: \n"," \n","\n","\n","Term: \n"," pitymys pinetorum\n","Sentence: \n"," \n","\n","\n","Term: \n"," vibrate\n","MAP@1 score: 0.9820841551610783\n"]}]},{"cell_type":"code","source":["# export test data split to re-test on full RAG pipeline\n","wordnet_test_df.to_csv(\"wordnet_test_df.csv\", index=False)"],"metadata":{"id":"D4HroHlQGcZw"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}